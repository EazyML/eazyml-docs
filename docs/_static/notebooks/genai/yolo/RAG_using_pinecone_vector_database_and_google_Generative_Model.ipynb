{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple eazyml-genai\n",
    "!pip install gdown python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from eazyml_genai.components import PDFLoader\n",
    "from eazyml_genai.components import PineconeDB\n",
    "from eazyml_genai.components import GoogleGM\n",
    "from eazyml_genai.components import(\n",
    "    OpenAIEmbeddingModel,\n",
    "    GoogleEmbeddingModel,\n",
    "    HuggingfaceEmbeddingModel,\n",
    "    HuggingfaceEmbeddingProcessor\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read PDF documents\n",
    "process pdf documents with unstructured data into semi-structured data or in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PDFLoader(max_chunk_words=1000)\n",
    "documents = pdf_loader.load(file_path=r'data/yolo.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your api key below\n",
    "os.environ['GEMINI_API_KEY'] = os.getenv('GEMINI_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['PINECONE_API_KEY'] = os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Document\n",
    "Pinecone vector database could be initialized in 2 ways:\n",
    "\n",
    "1. ```python\n",
    "    pine_db = PineconeDB(api_key=os.getenv(\"PINECONE_API_KEY\"))\n",
    "    ```\n",
    "2. ```python\n",
    "    pine_db = PineconeDB(api_key=\"pclocal\", host=\"http://localhost:5080\")\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pine_db = PineconeDB(api_key=\"pclocal\", host=\"http://localhost:5080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'yolo'\n",
    "indexed_documents = pine_db.index_documents(\n",
    "                                collection_name=collection_name,\n",
    "                                documents=documents,\n",
    "                                text_embedding_model=HuggingfaceEmbeddingModel.ALL_MINILM_L6_V2,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Answer using Generative Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve documents based on given question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"number of convolutional layer\"\n",
    "results = pine_db.retrieve_documents(\n",
    "                                question=question\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payloads = [i['metadata'] for i in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate answer for question and retrieved documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_gm = GoogleGM(model=\"gemini-2.0-flash\",\n",
    "                     api_key=os.getenv('GEMINI_API_KEY'))\n",
    "response, input_tokens, output_tokens = google_gm.predict(question=question,\n",
    "                            payloads=payloads,\n",
    "                            show_token_details=True\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_response = google_gm.parse(response=response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parsed_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
